<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="description"
          content="Dexterous nonprehensile manipulation for pushing and pulling">
    <meta name="keywords" content="DexNoMa, Nonprehensile manipulation, dexterous hand">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>DexNoMa: Learning Geometry-Aware Nonprehensile Dexterous Manipulation</title>
  
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script> -->
    <!-- <script>
      window.dataLayer = window.dataLayer || [];
  
      function gtag() {
        dataLayer.push(arguments);
      }
  
      gtag('js', new Date());
  
      gtag('config', 'G-PYVRSFMDRL');
    </script> -->
  
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
          rel="stylesheet">
  
    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet"
          href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="icon" href="./static/images/favicon.svg">
    <!-- Bulma core (already on your page) -->
    <link rel="stylesheet"
    href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css">

    <!-- Bulma‑carousel add‑on -->
    <link rel="stylesheet"
    href="https://cdn.jsdelivr.net/npm/bulma-carousel@4.0.4/dist/css/bulma-carousel.min.css">
    <script defer
    src="https://cdn.jsdelivr.net/npm/bulma-carousel@4.0.4/dist/js/bulma-carousel.min.js"></script>

  
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
    <script id="MathJax-script" async
            src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    
  </head>

  <script>
    document.addEventListener('DOMContentLoaded', () => {
      bulmaCarousel.attach('#results-carousel', {
        slidesToScroll: 1,
        slidesToShow:   3,      // 3 panels visible like your screenshot
        loop: false,
        infinite: true,
        autoplay:       true,      // turn auto‑advance on
        autoplaySpeed:  7000,      // 7 000 ms between moves
        duration:       600,       // 600 ms slide animation
        pauseOnHover: true,
        align: 'center',        // keeps first/last nicely centred
      });
    });
  </script>

<script>
  document.addEventListener('DOMContentLoaded', () => {
  
    /* handles */
    const selector = document.getElementById('trajectory-selector');
    const iframe   = document.getElementById('trajectory-iframe');
  
    /* 1️⃣ simple pattern:  <value>.html lives in ./static/html/ */
    selector.addEventListener('change', e => {
      const file = `./static/html/${e.target.value}.html`;   // Ball → Ball.html
      iframe.src = file;                                     // swap viewer
    });
  
    /* -- optional: explicit map instead of naming pattern ----
    const MAP = {
        "Ball"      : "./static/html/ball_view.html",
        "Bottle-1"  : "./static/html/bottle_1_pose.html",
        "Bottle-2"  : "./static/html/bottle_2_pose.html",
    };
    selector.addEventListener('change', e => iframe.src = MAP[e.target.value]);
    ---------------------------------------------------------- */
  });
  </script>

  <script>
    document.addEventListener('DOMContentLoaded', () => {
    
      /* ---------- 1.  object list & filename map ---------- */
      const OBJECTS = ['Black Box', 'Blender', 'Bottle', 'Bowl', 'Cake', 'Camera', 'Coconut Water', 'Cookie Box', 'Cow', 'Lamp', 'Ranch', 'Spary', 'Toy Avocado', 'Vase'];      // dropdown labels
      const FILE_STEM = {                                    // label → file‑name stem
        'Black Box'     : 'blackbox',
        'Blender' : 'blender',
        'Bottle' : 'bottle',
        'Bowl' : 'bowl',
        'Cake' : 'cake',
        'Camera': 'camera',
        'Coconut Water': 'coconut',
        'Cookie Box': 'cookiebox',
        'Cow': 'cow',
        'Lamp': 'lamp',
        'Spary': 'meyers',
        'Ranch': 'ranch',
        'Toy Avocado': 'avocado', 
        'Vase': 'vase'
      };
    
      /* ---------- 2.  populate the <select> ---------- */
      const select = document.getElementById('scene-select-real');
      OBJECTS.forEach(name => {
        const opt       = document.createElement('option');
        opt.value       = name;
        opt.textContent = name;
        select.appendChild(opt);
      });
    
      /* ---------- 3.  cache handles to the three videos ---------- */
      const vid1 = document.getElementById('video-real-left');   // Direction 1
      const vid2 = document.getElementById('video-real-right');  // Direction 2
      const vid3 = document.getElementById('video-real-third');  // Direction 3 (give it a unique id!)
    
      /* helper to swap one <video>’s source, reload, autoplay */
      function swapVideo(videoElem, file) {
        videoElem.src = file;   // direct src swap is simplest ─ avoids <source> nodes :contentReference[oaicite:1]{index=1}
        videoElem.load();       // force the browser to fetch the new clip :contentReference[oaicite:2]{index=2}
        videoElem.play().catch(()=>{});   // autoplay (ignored if blocked)
      }
    
      /* ---------- 4.  main update function ---------- */
      window.updateVideosReal = function () {
        const label = select.value;
        const stem  = FILE_STEM[label];             // e.g. "Bottle-1" → "bottle-1"
        if (!stem) return;                          // safety guard
    
        swapVideo(vid1, `./static/videos/real/${stem}-dir1.mp4`);
        swapVideo(vid2, `./static/videos/real/${stem}-dir2.mp4`);
        swapVideo(vid3, `./static/videos/real/${stem}-dir3.mp4`);
      };
    
      /* ---------- 5.  initialise page with first object ---------- */
      select.selectedIndex = 0;     // default to first item
      updateVideosReal();           // show its videos immediately
    });
    </script>

<script>
  /* ==========================================================
     Nearest‑Neighbor comparison viewer  (5 examples, L/R videos)
     ========================================================== */
  const NUM_EXAMPLES = 4;                                    // total examples
  const VIDEO_DIR    = './static/videos/NN_comparision/';    // base path
  
  let select, videoLeft, videoRight;                         // will cache later
  
  /* ----------------------------------------------------------
     Build <option>  Example 1 … Example 5
     ---------------------------------------------------------- */
  function populateDropdown() {
    for (let i = 1; i <= NUM_EXAMPLES; i++) {
      const opt = document.createElement('option');
      opt.value = i;                  // 1 … 5
      opt.textContent = `Example ${i}`;
      select.appendChild(opt);
    }
  }
  
  /* ----------------------------------------------------------
     Swap the sources for both videos when a new example is chosen
     ---------------------------------------------------------- */
  function updateNNVideos() {
    const idx      = select.value;    // "1" – "5"
    const leftSrc  = `${VIDEO_DIR}NN-example${idx}-left.mp4`;
    const rightSrc = `${VIDEO_DIR}NN-example${idx}-right.mp4`;
  
    videoLeft.querySelector('source').src  = leftSrc;
    videoRight.querySelector('source').src = rightSrc;
  
    videoLeft.load();                 // reload the new files
    videoRight.load();
  }
  
  /* ----------------------------------------------------------
     Initialise once the DOM is ready
     ---------------------------------------------------------- */
  document.addEventListener('DOMContentLoaded', () => {
    // Cache the DOM nodes *after* they exist
    select     = document.getElementById('NN_comparision');
    videoLeft  = document.getElementById('nn-video-left');
    videoRight = document.getElementById('nn-video-right');
  
    populateDropdown();               // fill the dropdown
    select.addEventListener('change', updateNNVideos);  // wire the handler
    updateNNVideos();                 // show Example 1 by default
  });
  </script>

<script>
  /* ==========================================================
     DexNoMa vs. Pre‑trained Grasp Pose ‑‑ comparison viewer
     (independent of any “NN comparison” script that may exist)
     ========================================================== */
  (function () {
    const NUM_GRASP_EXAMPLES = 4;                              // total examples
    const VIDEO_DIR = './static/videos/grasp_comparision/';    // base path
  
    let select, videoLeft, videoRight;                         // DOM handles
  
    /* --------------------------------------------------------
       Build <option> elements:  Example 1 … Example 5
       -------------------------------------------------------- */
    function populateDropdown() {
      for (let i = 1; i <= NUM_GRASP_EXAMPLES; i++) {
        const opt = document.createElement('option');
        opt.value = i;                     // 1 … 5
        opt.textContent = `Example ${i}`;
        select.appendChild(opt);
      }
    }
  
    /* --------------------------------------------------------
       Update both video sources to match the selected example
       -------------------------------------------------------- */
    function updateGraspVideos() {
      const idx = select.value;            // "1" – "5"
      videoLeft .querySelector('source').src = `${VIDEO_DIR}grasp-example${idx}-left.mp4`;
      videoRight.querySelector('source').src = `${VIDEO_DIR}grasp-example${idx}-right.mp4`;
      videoLeft.load();
      videoRight.load();
    }
  
    /* --------------------------------------------------------
       Initialise once the DOM is ready
       -------------------------------------------------------- */
    document.addEventListener('DOMContentLoaded', () => {
      select     = document.getElementById('grasp_comparision');
      videoLeft  = document.getElementById('grasp-video-left');
      videoRight = document.getElementById('grasp-video-right');
  
      populateDropdown();                     // fill the menu
      select.addEventListener('change', updateGraspVideos);
  
      updateGraspVideos();                    // show Example 1 by default
    });
  
    // If the HTML still has onchange="updateVideosReal()", alias it:
    window.updateVideosReal = updateGraspVideos;
  })();
  </script>

<!-- ── Script (kept right after the block) ─────────────────────── -->
<script>
  document.addEventListener('DOMContentLoaded', () => {
    const toggle = document.getElementById('sliderToggleImage');
    const block  = document.getElementById('result-image-wrapper');
  
    if (!toggle || !block) {
      console.error('Toggle or image wrapper not found – check the IDs.');
      return;
    }
  
    /* initial state (visible if checkbox is pre‑checked) */
    block.style.display = toggle.checked ? 'block' : 'none';
  
    /* show / hide on slider change */
    toggle.addEventListener('change', e => {
      block.style.display = e.target.checked ? 'block' : 'none';
    });
  });
  </script>
  
  
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">DexNoMa: Learning Geometry-Aware Nonprehensile Dexterous Manipulation</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              Anonymous Authors
            </span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block" style="margin-right: 1rem;">   <!-- ← adds blank space -->
                <a href="static/pdfs/paper.pdf"
                   class="external-link button is-normal is-rounded">
                  <span class="icon"><i class="fas fa-file-pdf"></i></span>
                  <span>Paper&nbsp;Submission</span>
                </a>
              </span>
              
              <!-- Appendix button -->
              <span class="link-block">
                <a href="static/pdfs/Appendix.pdf"
                   class="external-link button is-normal is-rounded">
                  <span class="icon"><i class="fas fa-file-pdf"></i></span>
                  <span>Appendix</span>
                </a>
              </span>
              
            </div>
          </div>
            
        </div>
      </div>
    </div>
</section> 
          <div class="column has-text-centered">
            <div class="publication-links"> 
              <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://dexnoma.github.io/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <!-- <span class="link-block">
                <a href="https://dexnoma.github.io/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code(Coming Soon)</span>
                  </a>
              </span> -->
              <!-- <span class="link-block">
                <a href="https://dexnoma.github.io/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-twitter">
                  </span>
                  <span>Twitter(Coming Soon)</span>
                </a>
              </span> -->
              </div>
            </div>

<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item">
          <video poster autoplay muted loop playsinline>
            <source src="./static/videos/hero_teaser/teaser_box.mp4" type="video/mp4">
          </video>
        </div>

        <div class="item">
          <video poster autoplay muted loop playsinline>
            <source src="./static/videos/hero_teaser/teaser_avo.mp4" type="video/mp4">
          </video>
        </div>

        <div class="item">
          <video poster autoplay muted loop playsinline>
            <source src="./static/videos/hero_teaser/teaser_coconut.mp4" type="video/mp4">
          </video>
        </div>

        <div class="item">
          <video poster autoplay muted loop playsinline>
            <source src="./static/videos/hero_teaser/teaser_cow.mp4" type="video/mp4">
          </video>
        </div>

        <div class="item">
          <video poster autoplay muted loop playsinline>
            <source src="./static/videos/hero_teaser/teaser_lamp.mp4" type="video/mp4">
          </video>
        </div>

        <div class="item">
          <video poster autoplay muted loop playsinline>
            <source src="./static/videos/hero_teaser/teaser_bowl.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>



<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4" type="video/mp4">
      </video>
    </div>
  </div>
</section> -->


<section class="section">
  <div class="container is-max-desktop"> 
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          Nonprehensile manipulation, such as pushing and pulling, enables robots to move, align, or reposition objects that may be difficult to grasp due to their geometry, size, or relationship to the robot or the environment. Much of the existing work in nonprehensile manipulation relies on parallel-jaw grippers or tools such as rods and spatulas. Multi-fingered dexterous hands offer richer contact modes and versatility for handling diverse objects to provide stable support over the objects, which compensates for the difficulty of modeling the dynamics of nonprehensile manipulation. We propose Dexterous Nonprehensile Manipulation(DexNoMa), a method for nonprehensile manipulation which frames the problem as synthesizing and learning pre-contact dexterous hand poses that lead to effective pushing and pulling. We generate diverse hand poses via contact-guided sampling, filter them using physics simulation, and train a diffusion model conditioned on object geometry to predict viable poses. At test time, we sample hand poses and use standard motion planning tools to select and execute pushing and pulling actions. We perform 840 real-world experiments with an Allegro Hand, comparing our method to baselines. The results indicate that DexNoMa offers a scalable route for training dexterous nonprehensile manipulation policies. Our pre-trained models and dataset, including 1.3 million hand poses across 2.3k objects, will be open-source to facilitate further research. 
          <br>
          <br>
          <b>NOTE: </b>A tag on the index finger of the Allegro Hand in our recorded experiments videos could reveal personal information. To preserve double-blind review, 
          we have obscured this tag with a black box in every video on our website.
        </div>
      </div>
    </div>
  </div>
</section>
<!--Method-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="title is-3">Method Overview</h2>
      <img src="./static/images/method.png"
        class="interpolation-image"
        alt="Interpolate start reference image."/>
      <h2 class="subtitle has-text-centered">
      <div class="content has-text-justified">
        <p>
          <b>i. </b>We present a large-scale dataset of hand poses specifically for pushing or
          pulling, and leverage it to train a diffusion model.
        </p>
        <p>
          <b>ii. </b>During execution time, given an object, we obtain its basis
          point set representation and pass that to our trained diffusion model.
          This model synthesizes diverse floating pre-contact hand poses formed from our large-scale data generation
          pipeline. 
        </p>
        <b>iii. </b>Given these hand poses, we then check their feasibility in a physics simulator by adding the
        arm back in and performing motion planning. We rank the feasible hand poses (e.g., “3” is infeasible in
        the example here) and select the best performing one (e.g., “4” in our example) and execute it in the real world.
        </div>
      </h2>
    </div>
  </div>

  <!--Dataset Visualization-->
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="title is-3" style="text-align:start;">Dataset</h2>
      <div class="content has-text-justified">
        <p>
          Explore our generated pushing hand poses over divers objects.
        </p>
      </div>
      <!--Interactive Hand Poses-->
      <!-- <div class="mobile-message">
        <h3 class="title is-6">Mobile Device Detected</h3>
        <p>This interactive 3D visualization is optimized for desktop viewing. Please visit on a desktop device for the full experience.</p>
        <p>The visualization shows original and augmented camera position for robotic tasks.</p>
      </div> -->

      <div class="desktop-content">
        <div class="box mt-0 mb-0">
          <div class="columns is-centered">
            <div class="column is-narrow">
              <div class="field">
                <label class="label">Choose an object to visualiza the generated pushing hand poses:</label>
                <div class="control">
                  <div class="select">
                    <select id="trajectory-selector">
                      <option value="Ball">Ball</option>
                      <option value="Bottle-1">Bottle-1</option>
                      <option value="Bottle-2">Bottle-2</option>
                      <option value="Bowl">Bowl</option>
                      <option value="Box">Box</option>
                      <option value="Camera">Camera</option>
                      <option value="Can">Can</option>
                      <option value="Cellphone-1">Cellphone-1</option>
                      <option value="Cellphone-2">Cellphone-2</option>
                      <option value="Hammer">Hammer</option>
                      <option value="Jar-1">Jar-1</option>
                      <option value="Jar-2">Jar-2</option>
                      <option value="Knife">Knife</option>
                      <option value="Mug">Mug</option>
                      <option value="Pencil">Pencil</option>
                      <option value="Pillow">Pillow</option>
                      <option value="Toaster">Toaster</option>
                    </select>
                  </div>
                </div>
              </div>
            </div>
          </div>
          
          <div class="columns is-centered">
            <div class="column">
              <div id="trajectory-container" class="has-text-centered">
                <div class="html-embed-container" style="position: relative; padding-bottom: 80%; overflow: hidden;">
                  <iframe 
                    id="trajectory-iframe"
                    src="./static/html/Bottle-1.html" 
                    style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border: none; border-radius: 10px;">
                  </iframe>
                </div>
              </div>
            </div>
          </div>

          <div class="columns is-centered" style="margin-top:-5%;">
            <div class="column is-three-quarters">
              <p class="has-text-centered is-size-6" style="text-align:start;">
                Click and drag to rotate. Right click and drag to pan. Scroll up to zoom in. Scroll down to zoom out. For more controls, check the upper right hand corner.
              </p>
            </div>
          </div>
        </div>
      </div>

      <!--Visualization of the dataset-->
      </div>
      </div>

    </div>
  </div>

<!-- Method Comparisons -->
<div class="container is-max-desktop">
  <div class="hero-body">
    <h2 class="title is-3">Experiments</h2>
    <div class="content has-text-justified">
      <div class="content has-text-centered">
        <h3 class="title is-4">Execution with DexNoMa</h3>
       </div>
      <p>
        The vidoes below are rollouts of DexNoMa over 8 3D-printed objects and 6 off-the-shelf daily objects. We test three pushing
        directions for each of the object.
      </p>
    </div>
    
    <div class="columns is-centered is-vcentered">

      <div class="scene-container">
        <div class="dropdown-container">
          <label><strong>Object </strong></label>
          <select class="dropdown" id="scene-select-real" onchange="updateVideosReal()">
          </select>
        </div>
        <br/>    
      </div>
    </div>    
    <br/>    

    <div class="columns is-centered">
      <div class="column is-6 has-text-centered">
        <h3 class="title is-4">Direction 1</h3>
        <video id="video-real-left" width="98%" controls muted autoplay loop>
          <source src="./static/videos/real/blackbox-dir1.mp4" type="video/mp4">
        </video>
      </div>

      <div class="column is-6 has-text-centered">
        <h3 class="title is-4">Direction 2</h3>
        <video id="video-real-right" width="98%" controls muted autoplay loop>
          <source src="./static/videos/real/blackbox-dir2.mp4" type="video/mp4">
        </video>
      </div>

      <div class="column is-6 has-text-centered">
        <h3 class="title is-4">Direction 3</h3>
        <video id="video-real-third" width="98%" controls muted autoplay loop>
          <source src="./static/videos/real/blackbox-dir3.mp4" type="video/mp4">
        </video>
      </div>
    </div>

    <div class="content has-text-justified">
      <div class="content has-text-centered">
        <h3 class="title is-4">Baseline Comparision</h3>
     </div>
     <p>
          We compare DexNoMa with the following methods.
     </p>
     <p>
      <b>i. Pre-Trained Grasp Pose:</b> We use a pre-trained grasp synthesis model using
      NeRF. For each object, we train a NeRF representation, then query their pre-trained model
      for a grasp.
    </p>
    <p>
      <b>ii. Nearest Neighbor:</b> Given a test object, we find the training object with the most similar BPS
      representation (in terms of Euclidean distance) and retrieve its associated hand poses. We then do
      the same motion planning pipeline as in DexNoMa.
    </p>
    <p>
      <b>ii. DexNoMa w/o Ranking:</b> An ablation that excludes analytical ranking of hand poses (ignores
      Eq. 3) and executes a random feasible pose.
    </p>

    <!-- ── Toggle bar + hidden image ───────────────────────────────── -->
    <div class="toggle-container">
      <div class="slider-wrapper">
        <input  type="checkbox"
                class="slider-checkbox"
                id="sliderToggleImage">
        <label class="slider" for="sliderToggleImage"></label>
        <span class="slider-text"><b>Show Detailed Result Figure</b></span>
      </div>

      <!-- Result image (starts hidden) -->
      <div id="result-image-wrapper" style="display:none; margin-top:1rem;">
        <figure class="image has-text-centered">
          <img id="result-image"
              src="./static/images/bar_plot.png"
              alt="Result Plot"
              style="max-width:90%; margin:0 auto;">
          <figcaption class="is-size-6" style="margin-top:0.5rem;">
            Figure 6(in our paper): Nonprehensile manipulation success rates from DexNoMa and baselines, across different 3D printed
            (left) and daily objects (right), and with three directions evaluated. Each bar aggregates success rates from
            40 trials (left bar plot) and 30 trials (right bar plot). See Sec. 5.2 and 5.3 in our paper for more details.
            <br>
            <br>
          </figcaption>
        </figure>
      </div>
    </div>
    <br>
    <!-- ── Grasp Comparision ───────────────────────────────── -->
     <div class="columns is-centered is-vcentered">

      <div class="scene-container">
        <div class="dropdown-container">
          <label><strong>Comparision </strong></label>
          <select class="dropdown" id="grasp_comparision" onchange="updateVideosReal()">
          </select>
        </div>
        <br/>    
      </div>
    </div>    
    <br/>    

    <div class="columns is-centered">
      <div class="column is-6 has-text-centered">
        <h3 class="title is-5">DexNoma</h3>
        <video id="grasp-video-left" width="98%" controls muted autoplay loop>
          <source src="./static/videos/grasp_comparision/grasp-example1-left.mp4" type="video/mp4">
        </video>
      </div>

      <div class="column is-6 has-text-centered">
        <h3 class="title is-5">Pre-trained Grasp Pose</h3>
        <video id="grasp-video-right" width="98%" controls muted autoplay loop>
          <source src="./static/videos/grasp_comparision/grasp-example1-right.mp4" type="video/mp4">
        </video>
      </div>

    </div>
  </div>

      <div class="columns is-centered is-vcentered">

        <div class="scene-container">
          <div class="dropdown-container">
            <label><strong>Comparision </strong></label>
            <select class="dropdown" id="NN_comparision" onchange="updateVideosReal()">
            </select>
          </div>
          <br/>    
        </div>
      </div>    
      <br/>    
  
      <div class="columns is-centered">
        <div class="column is-6 has-text-centered">
          <h3 class="title is-5">DexNoma</h3>
          <video id="nn-video-left" width="98%" controls muted autoplay loop>
            <source src="./static/videos/NN_comparision/NN-example1-left.mp4" type="video/mp4">
          </video>
        </div>
  
        <div class="column is-6 has-text-centered">
          <h3 class="title is-5">Nearest Neighbor</h3>
          <video id="nn-video-right" width="98%" controls muted autoplay loop>
            <source src="./static/videos/NN_comparision/NN-example1-right.mp4" type="video/mp4">
          </video>
        </div>
  
      </div>
    </div>

    <div class="content has-text-centered">
       <h3 class="title is-4">Multi-step Planning</h3>
    </div>
    <p>
      DexNoMa can be used to perform multiple pushes. The videos below show two multi-step pushing sequences using DexNoMa.
      The robot uses two different hand poses to push the 3D-printed vase in the left video, as the first hand pose may not
      be ideal for the second hand pose, which shows the benefit of re-planning.
    </p>
    <br>

    <div class="columns is-centered">
      <!-- Left column -->
      <div class="column is-6 has-text-centered">
        <!-- <h3 class="title is-4">DexNoMa</h3> -->
        <video id="multistep-video-left" width="100%" controls muted autoplay loop>
          <source src="static/videos/multi_step/multistep1.mp4" type="video/mp4">
        </video>
      </div>
    
      <!-- Right column -->
      <div class="column is-6 has-text-centered">
        <!-- <h3 class="title is-4">Pre‑trained Grasp Pose</h3> -->
        <video id="multistep-video-right" width="100%" controls muted autoplay loop>
          <source src="static/videos/multi_step/multistep2.mp4" type="video/mp4">
        </video>
      </div>
    </div>

    <h2 class="title is-3">Failure Modes</h2>
    <p>
      DexNoMa still exhibits several limitations and failure modes.
    </p>
    <b>i. </b>Some rollouts are with nearly collision with our method. However, our evaluation metrics for real world experiments doesn't
      quite take such collision into consideration, which may potentially cause damage to the Allegro Hand. 
    <p>
    <p>
      <b>ii. </b>Our method fails with object toppling. However, since our focus is on nonprehensile hand pose generation, we 
      didn't inverstigate too much into the toppling casued by factors such as firction, center of mass etc. We leave a more detailed investigation of 
      how physical properties influence dexterous nonprehensile manipulation as future work.
    </p>
    <br>
    </p>
    <div class="content has-text-justified">
      <div class="columns is-centered">
        <!-- Left column -->
        <div class="column is-6 has-text-centered">
          <!-- <h3 class="title is-4">DexNoMa</h3> -->
          <video id="multistep-video-left" width="100%" controls muted autoplay loop>
            <source src="static/videos/failure/failure-collision.mp4" type="video/mp4">
          </video>
          <p>
            Nearly Collision
          </p>
        </div>
      
        <!-- Right column -->
        <div class="column is-6 has-text-centered">
          <!-- <h3 class="title is-4">Pre‑trained Grasp Pose</h3> -->
          <video id="multistep-video-right" width="100%" controls muted autoplay loop>
            <source src="static/videos/failure/failure-toppling.mp4" type="video/mp4">
          </video>
          <p>
            Toppling
          </p>
        </div>
      </div>
    </div>

  </div>
</div>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <!-- <button class="copy-button" onclick="copyText()">Copy</button> -->
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            Design and source code from <a href="https://nerfies.github.io/">Nerfies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
